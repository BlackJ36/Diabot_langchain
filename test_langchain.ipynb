{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-08T13:34:13.094013400Z",
     "start_time": "2024-03-08T13:34:10.426569Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AIMessage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 83\u001B[0m\n\u001B[0;32m     80\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     81\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [SystemMessage(content\u001B[38;5;241m=\u001B[39mcorrector_template)] \u001B[38;5;241m+\u001B[39m last_message\n\u001B[1;32m---> 83\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mparse\u001B[39m(ai_message: \u001B[43mAIMessage\u001B[49m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m AgentState:\n\u001B[0;32m     84\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Parse the AI message.\"\"\"\u001B[39;00m\n\u001B[0;32m     85\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m:ai_message\u001B[38;5;241m.\u001B[39mcontent}\n",
      "\u001B[1;31mNameError\u001B[0m: name 'AIMessage' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from uuid import uuid4\n",
    "\n",
    "# The base setting of api\n",
    "unique_id = uuid4().hex[0:8]\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\" Corrector_agent_test_38\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"ls__eb24c4743a814171b07dc0591921a299\"  # Update to your API key\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
    "# Used by the agent in this tutorial\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-OqlsJwGTMdD1ujTG02Bb0fE08b7f4b30B07d8e83012bA8A8\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://oneapi.xty.app/v1\"\n",
    "\n",
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain.agents.format_scratchpad import format_to_openai_function_messages\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, BaseMessage, FunctionMessage, HumanMessage\n",
    "import operator\n",
    "from typing import Annotated, List, Sequence, Tuple, TypedDict, Union\n",
    "\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing_extensions import TypedDict\n",
    "from tools.robot_func import python_repl\n",
    "\n",
    "tools = [python_repl]\n",
    "# corrector_prompt\n",
    "corrector_prompt = hub.pull(\"blackj/corrector_prompt\")\n",
    "# print(corrector_prompt)\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "# corrector_prompt\n",
    "# tools = []\n",
    "# print(corrector_prompt.messages)\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    corrector_state: bool\n",
    "\n",
    "\n",
    "corrector_template = \\\n",
    "    \"\"\"You job is to make the user_requirenment clear.\n",
    "\n",
    "Just Output the Result,dont output decription.Dont make judge but help. \n",
    "\n",
    "You should work as the procedure including in the ###\n",
    "\n",
    "### 1. Interpret the Command of user: Analyze the user's input to determine if they want the robot to \"Get\" something or \"Go\" somewhere. Be aware that abbreviations might be used. \n",
    "\n",
    "Example: Interpret \"GO\" as \"go to\", and \"MV\" as \"move to\". ###\n",
    "\n",
    "###\n",
    "\n",
    "2. Correct and Clarify: Look for any spelling errors in the user's command that might indicate a specific location or item, it might something or somewhere in the house. Clarify the command without adding extra information. Note: Focus solely on the user's input for this step. Action: Correct any spelling mistakes and clarify the meaning of places or items mentioned.\n",
    "\n",
    "Example: User Input: \"Robt, GO to the kithcn and gt me a sppon.\" Corrected Command: \"Robot,go to the kitchen and get me a spoon.\" ###\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def correct_user_input(state:AgentState):\n",
    "    last_message = state[\"messages\"]\n",
    "    if state[\"corrector_state\"]:\n",
    "        return [SystemMessage(\n",
    "            content=f\"The user has confirm the command,I will send it to robot!!,the corrector command is {state['message'][-2]}\",\n",
    "            kwarg={\"corrector_state\": True})] + last_message\n",
    "    else:\n",
    "        return [SystemMessage(content=corrector_template)] + last_message\n",
    "\n",
    "def parse(ai_message: AIMessage) -> AgentState:\n",
    "    \"\"\"Parse the AI message.\"\"\"\n",
    "    return {\"messages\":ai_message.content}\n",
    "\n",
    "# llm_with_tool = llm.bind_tools(tools)\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "# \n",
    "# corrector_chain = correct_user_input | llm | StrOutputParser()\n",
    "# corrector_test = (\n",
    "#     {\"user_requirenment\": lambda x: x[\"input\"]}\n",
    "#         | corrector_prompt \n",
    "#         | llm \n",
    "#         | StrOutputParser())\n",
    "# \n",
    "# corrector_test.invoke({\"input\":\"robot,get tea\"})\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pyautogen",
   "language": "python",
   "display_name": "pyautogen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
